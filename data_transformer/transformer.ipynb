{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:33:32.721423Z",
     "start_time": "2024-01-11T20:33:29.328087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/11 21:33:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------------------+---------+----------+\n",
      "|      date|hour|          visitors|    unite|id_capteur|\n",
      "+----------+----+------------------+---------+----------+\n",
      "|2023-12-01|   0|               6.2|visiteurs|      NULL|\n",
      "|2023-12-01|   1|             887.0|visiteurs|      NULL|\n",
      "|2023-12-01|   2|1767.8000000000002|visiteurs|      NULL|\n",
      "|2023-12-01|   3|2648.6000000000004|visiteurs|      NULL|\n",
      "|2023-12-01|   4|          -17647.0|visiteurs|      NULL|\n",
      "+----------+----+------------------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataTransformer\").getOrCreate()\n",
    "df = spark.read.csv(\"../extractor_consumer/data/raw/*\", header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+----------+\n",
      "|      date|          visitors|    unite|id_capteur|\n",
      "+----------+------------------+---------+----------+\n",
      "|2023-01-01|           53108.0|visiteurs|      NULL|\n",
      "|2023-01-02|           37780.0|visiteurs|      NULL|\n",
      "|2023-01-03|           38226.4|visiteurs|      NULL|\n",
      "|2023-01-04|38672.799999999996|visiteurs|      NULL|\n",
      "|2023-01-05|39119.200000000004|visiteurs|      NULL|\n",
      "+----------+------------------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "ag_df = df.groupby(\"date\").agg(F.sum(F.col(\"visitors\")).alias(\"visitors\"),\n",
    "                       F.first(F.col(\"unite\")).alias(\"unite\"),\n",
    "                       F.first(F.col(\"id_capteur\")).alias(\"id_capteur\"))\n",
    "ag_df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:33:33.208538Z",
     "start_time": "2024-01-11T20:33:32.722168Z"
    }
   },
   "id": "1bbef8259c5d7da6",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de lignes sans compte de visiteurs :  0\n"
     ]
    },
    {
     "data": {
      "text/plain": "373"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\"\"nombre de lignes sans compte de visiteurs :  {ag_df.where(F.col(\"visitors\").isNull()).count()}\"\"\")\n",
    "ag_df = ag_df.drop(\"id_capteur\") # drops na col\n",
    "ag_df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:33:33.665801Z",
     "start_time": "2024-01-11T20:33:33.206962Z"
    }
   },
   "id": "a3778c00e163731",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+----------------+\n",
      "|      date|          visitors|    unite|moyenne_roulante|\n",
      "+----------+------------------+---------+----------------+\n",
      "|2023-01-01|           53108.0|visiteurs|            NULL|\n",
      "|2023-01-02|           37780.0|visiteurs|            NULL|\n",
      "|2023-01-03|           38226.4|visiteurs|            NULL|\n",
      "|2023-01-04|38672.799999999996|visiteurs|            NULL|\n",
      "|2023-01-05|39119.200000000004|visiteurs|            NULL|\n",
      "+----------+------------------+---------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "win_df = (( \n",
    "    ag_df\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"date\"))\n",
    "    .withColumn(\"moyenne_roulante\", F.mean(\"visitors\").over(Window.partitionBy(\"day_of_week\").orderBy(\"date\").rowsBetween(-4, -1)))\n",
    "    .drop(\"day_of_week\")\n",
    "    .orderBy(\"date\")   \n",
    "))\n",
    "win_df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:33:33.942153Z",
     "start_time": "2024-01-11T20:33:33.665353Z"
    }
   },
   "id": "8019aa8c9b93fc2d",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+------------------+----------+\n",
      "|      date|          visitors|    unite|  moyenne_roulante|pct_change|\n",
      "+----------+------------------+---------+------------------+----------+\n",
      "|2023-01-01|           53108.0|visiteurs|              NULL|      NULL|\n",
      "|2023-01-02|           37780.0|visiteurs|              NULL|      NULL|\n",
      "|2023-01-03|           38226.4|visiteurs|              NULL|      NULL|\n",
      "|2023-01-04|38672.799999999996|visiteurs|              NULL|      NULL|\n",
      "|2023-01-05|39119.200000000004|visiteurs|              NULL|      NULL|\n",
      "|2023-01-06|           39565.6|visiteurs|              NULL|      NULL|\n",
      "|2023-01-07|           40012.0|visiteurs|              NULL|      NULL|\n",
      "|2023-01-08|           31154.0|visiteurs|           53108.0|    -41.34|\n",
      "|2023-01-09|           40904.8|visiteurs|           37780.0|      8.27|\n",
      "|2023-01-10|41133.600000000006|visiteurs|           38226.4|      7.61|\n",
      "|2023-01-11|           39284.8|visiteurs|38672.799999999996|      1.58|\n",
      "|2023-01-12|           37244.0|visiteurs|39119.200000000004|     -4.79|\n",
      "|2023-01-13|37690.399999999994|visiteurs|           39565.6|     -4.74|\n",
      "|2023-01-14|38136.799999999996|visiteurs|           40012.0|     -4.69|\n",
      "|2023-01-15|           58524.0|visiteurs|           42131.0|     38.91|\n",
      "|2023-01-16|           39029.6|visiteurs|           39342.4|      -0.8|\n",
      "|2023-01-17|           39476.0|visiteurs|           39680.0|     -0.51|\n",
      "|2023-01-18|39922.399999999994|visiteurs|           38978.8|      2.42|\n",
      "|2023-01-19|39722.799999999996|visiteurs|38181.600000000006|      4.04|\n",
      "|2023-01-20|40815.200000000004|visiteurs|           38628.0|      5.66|\n",
      "+----------+------------------+---------+------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "pct_df = ((\n",
    "    win_df\n",
    "    .withColumn(\"pct_change\", F.round((100 * (F.col(\"visitors\") - F.col(\"moyenne_roulante\"))/(F.col(\"moyenne_roulante\"))), 2))\n",
    "))\n",
    "pct_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:37:36.004679Z",
     "start_time": "2024-01-11T20:37:35.863868Z"
    }
   },
   "id": "8c72e4e98958ac7",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
